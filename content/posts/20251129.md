---
title: "Better way to code with AI"
date: 2025-11-29
draft: true
---

Weâ€™ve all seen the charts. AI benchmarks are skyrocketing. SWE-Bench scores are climbing, and models are supposedly solving complex GitHub issues left and right. Yet, when we actually sit down to code with an LLM, the reaction is often... mixed.

*â€œWhy did it import a library that doesnâ€™t exist?â€*
*â€œWhy is it refactoring my code by just moving lines around?â€*
*â€œWait, did it just use a string for a boolean flag?â€*

If youâ€™ve ever felt like AI is brilliant in theory but frustrating in practice, you arenâ€™t alone. Based on a recent talk by **Dongjae Lee** (AI Champion and author of VeriSafe Agent), here is the definitive guide to crossing the gap between "AI hype" and "AI productivity."

---

## The "Manager" Mindset

The biggest mistake developers make is treating AI like a magic wand. Dongjaeâ€™s core thesis is simple: **Using AI well means becoming a Good Manager.**

Imagine a stereotypical middle manager. They delegate, they verify, and they handle resources. To get the most out of AI, you need to stop acting like a solo coder and start acting like a manager of a team of junior engineers (who happen to be GPUs).

Here are the three pillars of AI Management:

### 1. Know Your Employees (The Models)
Just like human employees, different models have different "personalities" and skill sets.
*   **The Reader:** If you need to process a PDF, know how they "read." GPT extracts text (losing layout), Claude uses OCR (better for text extraction), but Gemini processes the PDF as images (visual context).
*   **The Coder vs. The Generalist:** Claude (specifically Sonnet/Opus) is often hyper-optimized for coding tasks but might lack general knowledge breadth compared to GPT-4o or Gemini.

### 2. Divide and Conquer (Parallelism)
There is a concept in computing called **Amdahlâ€™s Law**. In the context of AI, it asks: *Is this a task I absolutely must do myself?*

If the answer is "No," delegate it.
*   **Human Tasks:** Creating the PowerPoint, writing the core thesis of a paper, designing high-level system architecture.
*   **AI Tasks:** Implementing the optimization function, generating plots for the paper, researching libraries.

**Pro Tip:** AI allows for **parallelism**. While you are prepping for a meeting, Agent 1 can be writing the optimization logic, and Agent 2 can be writing the visualization code.
*Warning:* Be careful of merge conflicts. If Agents A and B edit the same file, the diffs will break. Keep their tasks modular and separate.

### 3. Clear Instructions (The Spec)
If you give a vague command, you get vague code. A good manager gives a clear spec.
*   **Context:** Why are we doing this?
*   **Goal:** What is the specific output?
*   **Constraints:** Which files should be modified?
*   **Verification:** How do we know it works? (Provide a test command).

---

## Tactical Tips for Better AI Code

Okay, the high-level management stuff is great, but how do we actually stop the AI from hallucinating APIs? Here are some battle-tested tactics.

### Tip #1: Provide the Skeleton and Types First
Don't just say "Build a caching system." Give the AI the structure.
*   Define your **Classes** and **Data Types** upfront.
*   Write the function signatures (arguments and return types) yourself.
*   **Then** ask the AI to fill in the `...` (implementation details).

**Example:**
```python
# Give this to the AI first!
class SpecDB:
    def __init__(self, embedding_model: Optional[EmbeddingModel] = None): ...

    def query(self, sig: str) -> list[State]:
        raise NotImplementedError
```
By constraining the types, you prevent the AI from inventing data structures that don't fit your system.

### Tip #2: Hand It the Tools to Debug
AI struggles to debug because it can't "see" what's happening inside the execution. Help it out.
*   **Python:** Implement `__str__` magic methods so objects print nicely.
*   **OCaml/C++:** Write pretty-print functions.
*   **Tests:** Provide a unit test (even a simple input/output example) *before* asking for the code. Tell the AI: *"Keep adding test cases until you hit 95% coverage."*

### Tip #3: The "Plan Mode"
Before the AI writes a single line of code, ask it to generate a **Plan**.
*   If the requirements are vague, force the AI to ask you questions.
*   *Example Interaction:*
    *   **You:** "Convert python signatures to Dafny signatures."
    *   **AI:** "Should I convert Python `list` to a Dafny `array` or `seq`?"
    *   **You:** "Use `seq`."
*   This small back-and-forth prevents massive rewrites later.

### Tip #4: Rules and Conventions
If you are tired of renaming variables, create a rule set (system prompt) for your AI:
*   Variables = `snake_case`
*   Classes = `PascalCase`
*   Booleans must start with `is_`, `has_`, `can_`
*   "Use early returns"

---

## The Hard Truth: Intent Alignment

Even with all these tips, AI coding is hard. Why? Because **aligning intent is hard.**

If you ask a human expert to "Make a C program static analyzer," they will have a million questions. If you ask an AI, it will just start guessing. A small misunderstanding at the start leads to a massive divergence in the final code (the "Butterfly Effect" of coding).

**The Reality:**
To use AI effectively for large-scale tasks, we have to return to **Software Engineering 101**.
*   Functional Requirements (Input/Output specs).
*   Non-functional Requirements (Performance, Security).
*   Checking for ambiguity and conflicts.

Ironically, writing a spec distinct enough for an AI to execute perfectly is almost as difficult as writing the code yourself. This is the current bottleneck.

## Summary

1.  **Practice:** You need to "train" yourself to use AI, just like learning a new IDE.
2.  **Communicate:** The hardest problem is conveying your intent clearly.
3.  **Collaborate:** AI is not a replacement; it's a subordinate. You still need to coordinate, review, and guide.

So next time you open your IDE, don't just be a coder. Be a manager. Put on your "Kim Bu-jang" (Manager Kim) hat, assign the tasks, define the specs, and watch your productivity fly. ðŸš€